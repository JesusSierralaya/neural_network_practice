{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZzYyPZVHVix"
   },
   "source": [
    "# Perceptron Multicapa con clasificador multicategórico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7BP6MJ5IG9-e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Leire\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "# importamos librerías necesarias\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# versiones de los paquetes\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YcxG8ACgLwKo"
   },
   "outputs": [],
   "source": [
    "# Definimos funciones\n",
    "\n",
    "# esta funcion nos va a servir para ver la historia de la red\n",
    "# como ha ido cambiando el loss y el accuracy\n",
    "\n",
    "def plot_history(history):\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  hist['epoch'] = history.epoch\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Square Error')\n",
    "  plt.plot(hist['epoch'], hist['loss'],'r--',\n",
    "           label='Training Error')\n",
    "  plt.plot(hist['epoch'], hist['accuracy'],'b',\n",
    "           label = 'accuracy')\n",
    "  #plt.ylim([0,20])\n",
    "  plt.legend()\n",
    "  plt.show() # un €"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rsg2Lpd5HDTQ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Los datos ya estan incorporados en Keras, los cargamos con esta función\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# visualizamos la imagen 8\n",
    "plt.imshow(x_train[8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgluGv1-MHmN"
   },
   "source": [
    "Fíjate que en una única llamada a mnist.load_data() hemos cargado todo, los conjuntos de entrenamiento (x_train, y_train) y los conjuntos de evaluación (x_test, y_test)\n",
    "\n",
    "No te preocupes mucho, simplemente Keras ha definido la carga de esos ficheros de esa manera.\n",
    "\n",
    "La última parte del código sirve para visualizar las imágenes\n",
    "\n",
    "\n",
    "```\n",
    "# visualizamos la imagen 8\n",
    "plt.imshow(x_train[8])\n",
    "plt.show()\n",
    "```\n",
    "Si cambias el número 8 puedes ir viendo otras imágenes, tienes 60000 para elegir. Aunque aparezca en color es por la función usada imshow que las colorea, en realidad son escala de grises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tL6bkamUHn0M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(60000, 28, 28)\n",
      "1\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "# comprobamos las caracteristicas del set de entrenamiento\n",
    "print(x_train.ndim)\n",
    "print(x_train.shape)\n",
    "print(y_train.ndim)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILaGi6JDNxe6"
   },
   "source": [
    "Las dimensiones son las correctas, x es una matriz de 3 dimensiones: 60000x28x28 e y un vector de 600000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "w91wnzxdNnsF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensiones:  60000 10000 28 28\n"
     ]
    }
   ],
   "source": [
    "# guardamos las dimensiones en variables para hacer la red mas generica\n",
    "# y reutilizable\n",
    "\n",
    "ntrain = x_train.shape[0]\n",
    "ntest  = x_test.shape[0]\n",
    "dimf = x_train.shape[1]\n",
    "dimc = x_train.shape[2]\n",
    "\n",
    "print(\"dimensiones: \", ntrain, ntest, dimf, dimc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLrz7AcWOVJV"
   },
   "source": [
    "##Preprocesado\n",
    "\n",
    "Hay que preparar las imágenes para que entren en la red, vamos a hacer dos cosas:\n",
    "1. Vectorizarlas\n",
    "1. Normalizarlas, haciendo que vayan de 0 a 1 en vez de 0 a 255\n",
    "1. Convertir y en una matriz one hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EbBtxVf3OmJT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Preprocesamos los datos vectorizando y normalizando las imagenes\n",
    "\n",
    "x_train = x_train.astype('float32')/255.\n",
    "x_train = x_train.reshape(ntrain, dimf*dimc)\n",
    "\n",
    "x_test = x_test.astype('float32')/255.\n",
    "x_test = x_test.reshape(ntest, dimf*dimc)\n",
    "\n",
    "# comprobamos que la dimension de x es correcta\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HF4VZdQPPBuf"
   },
   "source": [
    "Ahora tenemos 60000 vectores de 784 (28x28) píxeles\n",
    "\n",
    "\n",
    "Creamos con y la matriz de onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "keQpY6s2PHey"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "4oir9PxVPdyr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Especificamos el modelo\n",
    "# Una unica capa oculta con 10 sigmoides\n",
    "# Una capa de salida con 10 softmax, una para cada categoria\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(dimf*dimc,)))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "JHmjFJU4RxoE"
   },
   "outputs": [],
   "source": [
    "# compilamos el modelo\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"sgd\", # stochastic gradient descent\n",
    "              metrics= ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "bwULGARUY8Zi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    }
   ],
   "source": [
    "# compilamos el modelo\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer= tf.keras.optimizers.RMSprop(lr=0.001),\n",
    "              metrics= ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "HrhKIgtGR7NQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60/60 [==============================] - 1s 6ms/step - loss: 0.7063 - accuracy: 0.8270\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.3227 - accuracy: 0.9111\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.2607 - accuracy: 0.9270\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.2238 - accuracy: 0.9377\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.1970 - accuracy: 0.9448\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.1770 - accuracy: 0.9500\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.1593 - accuracy: 0.9543\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.1448 - accuracy: 0.9592\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.1320 - accuracy: 0.9631\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.1220 - accuracy: 0.9656\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.1129 - accuracy: 0.9682\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.1044 - accuracy: 0.9705\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0974 - accuracy: 0.9723\n",
      "Epoch 14/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0913 - accuracy: 0.9749\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0854 - accuracy: 0.9757\n",
      "Epoch 16/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0803 - accuracy: 0.9776\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0746 - accuracy: 0.9794\n",
      "Epoch 18/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0711 - accuracy: 0.9803\n",
      "Epoch 19/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0670 - accuracy: 0.9816\n",
      "Epoch 20/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0632 - accuracy: 0.9826\n",
      "Epoch 21/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0601 - accuracy: 0.9837\n",
      "Epoch 22/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0570 - accuracy: 0.9846\n",
      "Epoch 23/100\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.0541 - accuracy: 0.9855\n",
      "Epoch 24/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0513 - accuracy: 0.9858\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0492 - accuracy: 0.9865\n",
      "Epoch 26/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0465 - accuracy: 0.9877\n",
      "Epoch 27/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0444 - accuracy: 0.9882\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0422 - accuracy: 0.9891\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.0405 - accuracy: 0.9894\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.0386 - accuracy: 0.9904\n",
      "Epoch 31/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0368 - accuracy: 0.9908\n",
      "Epoch 32/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0350 - accuracy: 0.9911\n",
      "Epoch 33/100\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.0337 - accuracy: 0.9913\n",
      "Epoch 34/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0319 - accuracy: 0.9919\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0308 - accuracy: 0.9922\n",
      "Epoch 36/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0288 - accuracy: 0.9928\n",
      "Epoch 37/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0282 - accuracy: 0.9931\n",
      "Epoch 38/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0265 - accuracy: 0.9939\n",
      "Epoch 39/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0252 - accuracy: 0.9941\n",
      "Epoch 40/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0242 - accuracy: 0.9948\n",
      "Epoch 41/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0230 - accuracy: 0.9951\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0222 - accuracy: 0.9952\n",
      "Epoch 43/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0210 - accuracy: 0.9957\n",
      "Epoch 44/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0205 - accuracy: 0.9955\n",
      "Epoch 45/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0193 - accuracy: 0.9962\n",
      "Epoch 46/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0185 - accuracy: 0.9965\n",
      "Epoch 47/100\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.0176 - accuracy: 0.9968\n",
      "Epoch 48/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0171 - accuracy: 0.9969\n",
      "Epoch 49/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0161 - accuracy: 0.9971\n",
      "Epoch 50/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0154 - accuracy: 0.9974\n",
      "Epoch 51/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0147 - accuracy: 0.9978\n",
      "Epoch 52/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0140 - accuracy: 0.9979\n",
      "Epoch 53/100\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.0133 - accuracy: 0.9980\n",
      "Epoch 54/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0126 - accuracy: 0.9982\n",
      "Epoch 55/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0120 - accuracy: 0.9983\n",
      "Epoch 56/100\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 0.9985\n",
      "Epoch 57/100\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 0.9987\n",
      "Epoch 58/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0105 - accuracy: 0.9987\n",
      "Epoch 59/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0102 - accuracy: 0.9989\n",
      "Epoch 60/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0095 - accuracy: 0.9990\n",
      "Epoch 61/100\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.0093 - accuracy: 0.9991\n",
      "Epoch 62/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0086 - accuracy: 0.9993\n",
      "Epoch 63/100\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.0083 - accuracy: 0.9994\n",
      "Epoch 64/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0079 - accuracy: 0.9993\n",
      "Epoch 65/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0075 - accuracy: 0.9994\n",
      "Epoch 66/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0073 - accuracy: 0.9995\n",
      "Epoch 67/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0068 - accuracy: 0.9996\n",
      "Epoch 68/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0066 - accuracy: 0.9996\n",
      "Epoch 69/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 0.9996\n",
      "Epoch 70/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 0.9995\n",
      "Epoch 71/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 0.9998\n",
      "Epoch 72/100\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 0.9997\n",
      "Epoch 73/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 0.9998\n",
      "Epoch 74/100\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 0.9998\n",
      "Epoch 75/100\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.9998\n",
      "Epoch 76/100\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 0.9998\n",
      "Epoch 77/100\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 0.9999\n",
      "Epoch 78/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.9998\n",
      "Epoch 79/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 0.9998\n",
      "Epoch 80/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0036 - accuracy: 0.9999\n",
      "Epoch 82/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0035 - accuracy: 0.9999\n",
      "Epoch 83/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0034 - accuracy: 0.9999\n",
      "Epoch 84/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0032 - accuracy: 0.9999\n",
      "Epoch 85/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0031 - accuracy: 0.9999\n",
      "Epoch 86/100\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.0029 - accuracy: 0.9999\n",
      "Epoch 87/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0029 - accuracy: 0.9999\n",
      "Epoch 88/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0027 - accuracy: 0.9999\n",
      "Epoch 89/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 0.9999\n",
      "Epoch 91/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# hacemos el entrenamiento\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=100,  batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxYK4VwySE84"
   },
   "source": [
    "El batch_size no ha sido aún explicado, simplemente úsalo así, en esencia lo que estamos haciendo es utilizar lotes de 1000 y hacer el backpropagation, así se entrena la red mucho más rápido.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "yFHEcDzhSkdH"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hacemos un plot para ver si aprende adecuadamente\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "0Bbdw8veTzRG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0860 - accuracy: 0.9793\n",
      "test accuracy:  0.9793000221252441\n"
     ]
    }
   ],
   "source": [
    "# evaluacion final con el test_set\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Vpwvbz0UHSY"
   },
   "source": [
    "Aproximadamente un 83% de precisión en la clasificación. Está muy bien para ser matrices vectorizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqUxnBObVZyY"
   },
   "source": [
    "Vamos a ver la salida de la capa de neuronas softmax, la salida de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "r_bFixVoVizM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step\n",
      "[1.7949442e-03 7.2706162e-06 5.1162500e-02 7.0075337e-03 3.8208924e-02\n",
      " 3.9845826e-03 7.3918378e-01 4.5145398e-06 1.5826918e-01 3.7685226e-04]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "yp = model.predict(x_test)\n",
    "\n",
    "print(yp[11])\n",
    "print(np.argmax(yp[11]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIkI-133WCSk"
   },
   "source": [
    "La categoria final es la de la neurona que tenga el valor más alto. En este caso la 6 (en python se empieza a contar en 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XirSO5SWtWl"
   },
   "source": [
    "# Ejercicio\n",
    "\n",
    "Prueba a modificar los hiperparámetros de la red e incluso su arquitectura para obtener una mejor clasificación. Por ejemplo podrías hacer lo siguiente:\n",
    "\n",
    "1. Prueba a utilizar otros tipos de neuronas (RelU o tanh)\n",
    "1. Prueba a incrementar el número de capas y de neuronas\n",
    "1. Prueba a cambiar el batch_size\n",
    "1. Prueba a utilizar otros optimizadores como adam o RMSprop\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer= tf.keras.optimizers.Adam(lr=0.001),\n",
    "              metrics= ['accuracy'])\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer= tf.keras.optimizers.RMSprop(lr=0.001),\n",
    "              metrics= ['accuracy'])\n",
    "```\n",
    "\n",
    "\n",
    "Haz las pruebas que consideres interesantes e interpreta los resultados.\n",
    "\n",
    "Pega el código empleado (solo las partes que has cambiado) en la ventana de abajo\n",
    "\n",
    "Para saber cómo modificar la red o cambiar de optimizador simplemente usa google, te aportará miles de ejemplos\n",
    "\n",
    "Recuerda que los resultados tienes que subirlos a un cuestionario de moodle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modificación de las neuronas de activación\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando ReLU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7960 (31.09 KB)\n",
      "Trainable params: 7960 (31.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Una unica capa oculta con 10 ReLU\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(dimf*dimc,)))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3071 - accuracy: 0.9139\n",
      "test accuracy:  0.9139000177383423\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion final con el test_set\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando Tanh\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(tu codigo por aquí)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, manteniendo el mismo número de capas y neuronas (una capa y 10 neuronas), mientras que usando sigmoid se obtenía un *test accuracy* de 0.83, usando ReLU se ha obtenido un valor de 0.91 y usando Tanh --."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modificación del número de capas y de neuronas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando ReLU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_33 (Dense)            (None, 50)                39250     \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39760 (155.31 KB)\n",
      "Trainable params: 39760 (155.31 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Una unica capa oculta con 50 ReLU\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape=(dimf*dimc,)))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2777 - accuracy: 0.9221\n",
      "test accuracy:  0.9221000075340271\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion final con el test_set\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Una unica capa oculta con 100 ReLU\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(dimf*dimc,)))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2575 - accuracy: 0.9279\n",
      "test accuracy:  0.9279000163078308\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion final con el test_set\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                110       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8070 (31.52 KB)\n",
      "Trainable params: 8070 (31.52 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Dos capas ocultas con 10 ReLU cada una\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(dimf*dimc,)))\n",
    "model.add(Dense(10, activation='relu', input_shape=(dimf*dimc,)))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.3594 - accuracy: 0.8940\n",
      "test accuracy:  0.8939999938011169\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion final con el test_set\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 50)                39250     \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_25 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42310 (165.27 KB)\n",
      "Trainable params: 42310 (165.27 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Dos capas ocultas con 50 ReLU cada una\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape=(dimf*dimc,)))\n",
    "model.add(Dense(50, activation='relu', input_shape=(dimf*dimc,)))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.2281 - accuracy: 0.9323\n",
      "test accuracy:  0.9322999715805054\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion final con el test_set\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_30 (Dense)            (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89610 (350.04 KB)\n",
      "Trainable params: 89610 (350.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Dos capas ocultas con 100 ReLU cada una\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(dimf*dimc,)))\n",
    "model.add(Dense(100, activation='relu', input_shape=(dimf*dimc,)))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2191 - accuracy: 0.9381\n",
      "test accuracy:  0.9380999803543091\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion final con el test_set\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_49 (Dense)            (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 130010 (507.85 KB)\n",
      "Trainable params: 130010 (507.85 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Seis capas ocultas con 100 ReLU cada una\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(dimf*dimc,)))\n",
    "model.add(Dense(100, activation='relu', input_shape=(dimf*dimc,)))\n",
    "model.add(Dense(100, activation='relu', input_shape=(dimf*dimc,)))\n",
    "model.add(Dense(100, activation='relu', input_shape=(dimf*dimc,)))\n",
    "model.add(Dense(100, activation='relu', input_shape=(dimf*dimc,)))\n",
    "model.add(Dense(100, activation='relu', input_shape=(dimf*dimc,)))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1394 - accuracy: 0.9568\n",
      "test accuracy:  0.9567999839782715\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion final con el test_set\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lo que respecta a las neuronas ReLU, se puede observar que según aumenta el número de capas y de neuronas por capa, el valor del *test accuray* también aumenta. De hecho, el modelo alcanza su máximo porcentaje con 6 capas y 100 neuronas en cada una."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando Tanh\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(tu codigo por aquí)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modificación del batch_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando ReLU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.5873 - accuracy: 0.5271\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.7832 - accuracy: 0.8012\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5841 - accuracy: 0.8432\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5022 - accuracy: 0.8622\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4569 - accuracy: 0.8734\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4271 - accuracy: 0.8814\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.4054 - accuracy: 0.8867\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3888 - accuracy: 0.8910\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3756 - accuracy: 0.8946\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 1s 3ms/step - loss: 0.3649 - accuracy: 0.8977\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3561 - accuracy: 0.8999\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3485 - accuracy: 0.9018\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3420 - accuracy: 0.9040\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3364 - accuracy: 0.9052\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.9067\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3272 - accuracy: 0.9079\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3233 - accuracy: 0.9088\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3197 - accuracy: 0.9100\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3163 - accuracy: 0.9110\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3134 - accuracy: 0.9115\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3106 - accuracy: 0.9126\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3078 - accuracy: 0.9132\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3055 - accuracy: 0.9135\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3031 - accuracy: 0.9142\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3007 - accuracy: 0.9145\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2987 - accuracy: 0.9158\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2966 - accuracy: 0.9160\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2946 - accuracy: 0.9167\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2928 - accuracy: 0.9175\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2909 - accuracy: 0.9176\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2891 - accuracy: 0.9184\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2874 - accuracy: 0.9188\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2857 - accuracy: 0.9193\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2841 - accuracy: 0.9198\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2826 - accuracy: 0.9203\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2812 - accuracy: 0.9207\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2796 - accuracy: 0.9209\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2782 - accuracy: 0.9212\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2768 - accuracy: 0.9213\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2754 - accuracy: 0.9222\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2741 - accuracy: 0.9228\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2728 - accuracy: 0.9228\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2715 - accuracy: 0.9232\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2700 - accuracy: 0.9236\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2688 - accuracy: 0.9239\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2675 - accuracy: 0.9249\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2664 - accuracy: 0.9240\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2653 - accuracy: 0.9254\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2641 - accuracy: 0.9250\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2627 - accuracy: 0.9261\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2618 - accuracy: 0.9260\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2606 - accuracy: 0.9264\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2596 - accuracy: 0.9265\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2584 - accuracy: 0.9272\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2576 - accuracy: 0.9273\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2565 - accuracy: 0.9275\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2554 - accuracy: 0.9280\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2544 - accuracy: 0.9280\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2534 - accuracy: 0.9283\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2524 - accuracy: 0.9289\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.2515 - accuracy: 0.9287\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.2504 - accuracy: 0.9293\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2494 - accuracy: 0.9293\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.2485 - accuracy: 0.9296\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2475 - accuracy: 0.9300\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2466 - accuracy: 0.9310\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.2457 - accuracy: 0.9308\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2445 - accuracy: 0.9312\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2437 - accuracy: 0.9315\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2427 - accuracy: 0.9315\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2418 - accuracy: 0.9319\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2409 - accuracy: 0.9318\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2397 - accuracy: 0.9323\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2390 - accuracy: 0.9324\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.2379 - accuracy: 0.9329\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2370 - accuracy: 0.9329\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2360 - accuracy: 0.9337\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.2353 - accuracy: 0.9333\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2343 - accuracy: 0.9339\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.2334 - accuracy: 0.9340\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.2325 - accuracy: 0.9345\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2314 - accuracy: 0.9348\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.2306 - accuracy: 0.9350\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2297 - accuracy: 0.9353\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2288 - accuracy: 0.9352\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2279 - accuracy: 0.9358\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2270 - accuracy: 0.9363\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2262 - accuracy: 0.9366\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2253 - accuracy: 0.9364\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2244 - accuracy: 0.9365\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2236 - accuracy: 0.9369\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2228 - accuracy: 0.9374\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2219 - accuracy: 0.9376\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2211 - accuracy: 0.9378\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2204 - accuracy: 0.9378\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.2196 - accuracy: 0.9380\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.2190 - accuracy: 0.9382\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2183 - accuracy: 0.9389\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2174 - accuracy: 0.9388\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2170 - accuracy: 0.9388\n"
     ]
    }
   ],
   "source": [
    "# Hacer el entrenamiento con batch_size=100\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=100,  batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2394 - accuracy: 0.9311\n",
      "test accuracy:  0.9311000108718872\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion final con el test_set\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2.2320 - accuracy: 0.1546\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2.1564 - accuracy: 0.2131\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2.0833 - accuracy: 0.2693\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2.0090 - accuracy: 0.3222\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.9348 - accuracy: 0.3742\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.8635 - accuracy: 0.4265\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.7953 - accuracy: 0.4794\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.7294 - accuracy: 0.5249\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.6653 - accuracy: 0.5650\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.6025 - accuracy: 0.6002\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.5411 - accuracy: 0.6320\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.4811 - accuracy: 0.6575\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.4229 - accuracy: 0.6778\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.3668 - accuracy: 0.6944\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.3130 - accuracy: 0.7084\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.2619 - accuracy: 0.7193\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.2135 - accuracy: 0.7283\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.1680 - accuracy: 0.7367\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.1255 - accuracy: 0.7447\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.0858 - accuracy: 0.7511\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.0489 - accuracy: 0.7563\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0147 - accuracy: 0.7620\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.9830 - accuracy: 0.7672\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.9536 - accuracy: 0.7720\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.9262 - accuracy: 0.7765\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.9008 - accuracy: 0.7815\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.8772 - accuracy: 0.7859\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.8552 - accuracy: 0.7900\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8346 - accuracy: 0.7944\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.8154 - accuracy: 0.7983\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7974 - accuracy: 0.8023\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7805 - accuracy: 0.8049\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7646 - accuracy: 0.8089\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7496 - accuracy: 0.8120\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7355 - accuracy: 0.8148\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7222 - accuracy: 0.8178\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7096 - accuracy: 0.8205\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6976 - accuracy: 0.8230\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.8255\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6755 - accuracy: 0.8278\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6652 - accuracy: 0.8296\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6555 - accuracy: 0.8317\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6462 - accuracy: 0.8341\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.8357\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.8383\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6207 - accuracy: 0.8397\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6129 - accuracy: 0.8416\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6055 - accuracy: 0.8429\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5983 - accuracy: 0.8447\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5915 - accuracy: 0.8458\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5849 - accuracy: 0.8478\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5786 - accuracy: 0.8494\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5725 - accuracy: 0.8506\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5667 - accuracy: 0.8522\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.8533\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5556 - accuracy: 0.8544\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.8558\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.8567\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.8579\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.8590\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.8598\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.8605\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.8617\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5185 - accuracy: 0.8622\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.8630\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.8638\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.8650\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.8655\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.8662\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.8672\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.8678\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4898 - accuracy: 0.8686\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4867 - accuracy: 0.8692\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.8698\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.8704\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.8711\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.8719\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.8724\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.8729\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.8737\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.8743\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.8747\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.8752\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.8758\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.8762\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4530 - accuracy: 0.8768\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4509 - accuracy: 0.8774\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4487 - accuracy: 0.8780\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4467 - accuracy: 0.8783\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4447 - accuracy: 0.8788\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.8790\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.8793\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4389 - accuracy: 0.8799\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4371 - accuracy: 0.8803\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4353 - accuracy: 0.8807\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4336 - accuracy: 0.8810\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.8815\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4302 - accuracy: 0.8816\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4286 - accuracy: 0.8820\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4269 - accuracy: 0.8824\n"
     ]
    }
   ],
   "source": [
    "# Hacer el entrenamiento con batch_size=3000\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=100,  batch_size=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4072 - accuracy: 0.8879\n",
      "test accuracy:  0.8878999948501587\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion final con el test_set\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2892 - accuracy: 0.1432\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2305 - accuracy: 0.1770\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.1899 - accuracy: 0.2015\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.1558 - accuracy: 0.2196\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.1244 - accuracy: 0.2351\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.0943 - accuracy: 0.2503\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.0649 - accuracy: 0.2648\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.0357 - accuracy: 0.2795\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.0062 - accuracy: 0.2948\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.9758 - accuracy: 0.3090\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.9438 - accuracy: 0.3239\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.9096 - accuracy: 0.3386\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.8742 - accuracy: 0.3528\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.8384 - accuracy: 0.3709\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.8029 - accuracy: 0.3901\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.7676 - accuracy: 0.4127\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.7328 - accuracy: 0.4358\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.6985 - accuracy: 0.4613\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.6647 - accuracy: 0.4844\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.6313 - accuracy: 0.5079\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.5985 - accuracy: 0.5300\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.5664 - accuracy: 0.5488\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.5350 - accuracy: 0.5688\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.5042 - accuracy: 0.5850\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.4743 - accuracy: 0.6010\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.4451 - accuracy: 0.6147\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.4167 - accuracy: 0.6292\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.3891 - accuracy: 0.6424\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.3623 - accuracy: 0.6538\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.3363 - accuracy: 0.6641\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.3110 - accuracy: 0.6748\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.2864 - accuracy: 0.6845\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.2626 - accuracy: 0.6931\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.2395 - accuracy: 0.7015\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.2171 - accuracy: 0.7094\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.1952 - accuracy: 0.7163\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.1740 - accuracy: 0.7227\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.1534 - accuracy: 0.7287\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.1334 - accuracy: 0.7341\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.1138 - accuracy: 0.7398\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.0948 - accuracy: 0.7450\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.0761 - accuracy: 0.7495\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.0578 - accuracy: 0.7544\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.0399 - accuracy: 0.7586\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.0223 - accuracy: 0.7625\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.0049 - accuracy: 0.7671\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.9879 - accuracy: 0.7707\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.9713 - accuracy: 0.7739\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.9552 - accuracy: 0.7775\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.9394 - accuracy: 0.7810\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.9242 - accuracy: 0.7843\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.9094 - accuracy: 0.7875\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.8952 - accuracy: 0.7910\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.8814 - accuracy: 0.7937\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.8681 - accuracy: 0.7964\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.8552 - accuracy: 0.7989\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.8428 - accuracy: 0.8017\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.8308 - accuracy: 0.8039\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.8193 - accuracy: 0.8063\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.8081 - accuracy: 0.8085\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.7973 - accuracy: 0.8108\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.7869 - accuracy: 0.8129\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.7769 - accuracy: 0.8147\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.7672 - accuracy: 0.8166\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.7578 - accuracy: 0.8184\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.7488 - accuracy: 0.8199\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.7400 - accuracy: 0.8217\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.7315 - accuracy: 0.8233\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.7233 - accuracy: 0.8248\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.7154 - accuracy: 0.8261\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.7077 - accuracy: 0.8275\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.7003 - accuracy: 0.8290\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.8302\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6861 - accuracy: 0.8314\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6794 - accuracy: 0.8328\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6728 - accuracy: 0.8337\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6665 - accuracy: 0.8350\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6603 - accuracy: 0.8359\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6543 - accuracy: 0.8373\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6485 - accuracy: 0.8384\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6428 - accuracy: 0.8396\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.8404\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6320 - accuracy: 0.8413\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6269 - accuracy: 0.8424\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6218 - accuracy: 0.8430\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6169 - accuracy: 0.8441\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6122 - accuracy: 0.8449\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6075 - accuracy: 0.8457\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6030 - accuracy: 0.8462\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5986 - accuracy: 0.8470\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5943 - accuracy: 0.8476\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5901 - accuracy: 0.8486\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5861 - accuracy: 0.8493\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5821 - accuracy: 0.8498\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5782 - accuracy: 0.8504\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5744 - accuracy: 0.8509\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5708 - accuracy: 0.8518\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5672 - accuracy: 0.8523\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5636 - accuracy: 0.8530\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5602 - accuracy: 0.8536\n"
     ]
    }
   ],
   "source": [
    "# Hacer el entrenamiento con batch_size=5000\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=100,  batch_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.5350 - accuracy: 0.8598\n",
      "test accuracy:  0.8597999811172485\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion final con el test_set\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuando con la modificación del batch_size en la función ReLU usando una capa con 10 neuronas, se puede observar cómo, a medida que aumenta este, disminuye el *test accuracy*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando Tanh\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(tu codigo por aquí)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modificación de los optimizadores como adam o RMSprop\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando ReLU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    }
   ],
   "source": [
    "# Compilar el modelo usando RMSprop\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer= tf.keras.optimizers.RMSprop(lr=0.001),\n",
    "              metrics= ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.2510 - accuracy: 0.9307\n",
      "test accuracy:  0.9307000041007996\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion final con el test_set\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "# Compilar el modelo usando Adam\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer= tf.keras.optimizers.Adam(lr=0.001),\n",
    "              metrics= ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2311 - accuracy: 0.9373\n",
      "test accuracy:  0.9373000264167786\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion final con el test_set\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, en lo que respecta al uso de distintos optimizadores, si se emplean las mismas configuraciones que en el apartado anterior (una capa con 10 neuronas) y un batch_size de 1000, se puede observar cómo Adam es ligeramente más preciso que RMSprop, no obstante no es una diferencia importante. De hecho, cabe destacar que tras probar con varias configuaraciones (modificando el número de capas y neuronas) hemos visto que no hay diferencias entre usar uno u otro optimizador. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente, el valor de *test accuracy* máximo que se ha podido conseguir ha sido de 0.9793 usando una única capa con 100 neuronas, el optimizador RMSprop y un batch_size de 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando Tanh\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(tu codigo por aquí)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMy3u+3gQiuJMi8gYCXYnff",
   "collapsed_sections": [],
   "name": "P03.MLP_mnist_onehot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
